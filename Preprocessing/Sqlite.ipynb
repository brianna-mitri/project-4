{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sqlalchemy import create_engine\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open zipped file and read into df\n",
    "def unzip_to_df(zip_filepath, file_inside_zip, **read_csv_kwargs):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as z:\n",
    "            with z.open(file_inside_zip) as f:\n",
    "                df = pd.read_csv(f, dtype={'Manufacturer Code': str}, **read_csv_kwargs)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error occured: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df\n",
    "zip_path = 'Output/Delays/modeling_data_dest_narrow.zip'\n",
    "file_name = 'modeling_data_dest_narrow.csv'\n",
    "\n",
    "delays_df = unzip_to_df(zip_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a connection engine (SQLite version)\n",
    "engine = create_engine(\"sqlite:///delays_database.sqlite\")\n",
    "\n",
    "# Save the DataFrame to a table\n",
    "delays_df.to_sql(\"my_table\", con=engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all rows from the table\n",
    "df_from_db = pd.read_sql(\"SELECT * FROM delays\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dtype to int if bool\n",
    "bool_cols = [col for col in list(delays_df.columns) if delays_df[col].dtype == 'bool']\n",
    "\n",
    "# convert bool types to int64\n",
    "for bool in bool_cols:\n",
    "    delays_df[bool] = delays_df[bool].astype(np.int64)\n",
    "    print(f'{bool}: {delays_df[bool].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate \n",
    "t_name = 'Delay Bin'\n",
    "y_var = delays_df[t_name]\n",
    "x_vars = delays_df.drop(columns=t_name).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify categorical and numerical columns\n",
    "# get x cols list\n",
    "cols_list = list(x_vars.columns)\n",
    "\n",
    "# get numeric cols\n",
    "num_names = [\n",
    "    col for col in cols_list\n",
    "    if (x_vars[col].dtypes == 'int64' or x_vars[col].dtypes == 'float64')\n",
    "        and col.endswith('Missing') == False and col.endswith('Certificated') == False\n",
    "]\n",
    "\n",
    "# get categorical cols--> leftover\n",
    "cat_names = list(set(cols_list) - set(num_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_vars, y_var, \n",
    "    random_state=1,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    stratify=y_var  #b/c classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transformers for numeric and categorical columns separately\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(\n",
    "    drop='first',  #drop first createdcol\n",
    "    handle_unknown='ignore',  #prevents errors if test/new data has unforseen categories\n",
    "    sparse_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine transformers with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_names),  #apply onehotencoder to category cols\n",
    "        ('num', num_transformer, num_names)  #apply scaling to numeric cols\n",
    "    ],\n",
    "    #remainder='passthrough'  #keep rest of the cols untransformed\n",
    "    remainder='drop'  #drop rest of the columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit/transform on x train and transform x test --> avoid data leakage\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rebalancing on training set\n",
    "sm = SMOTE(random_state=1)\n",
    "x_train_bal, y_train_bal = sm.fit_resample(x_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affected column: Destination Sea Level Pressure Missing\n",
      "Unknown values: set()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delay Bin</th>\n",
       "      <th>Month (sin)</th>\n",
       "      <th>Month (cos)</th>\n",
       "      <th>Day (sin)</th>\n",
       "      <th>Day (cos)</th>\n",
       "      <th>Day of Week (sin)</th>\n",
       "      <th>Day of Week (cos)</th>\n",
       "      <th>Scheduled Departure Total Minutes (sin)</th>\n",
       "      <th>Scheduled Departure Total Minutes (cos)</th>\n",
       "      <th>Scheduled Elapsed Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination Relative Humidity</th>\n",
       "      <th>Destination Wind Speed</th>\n",
       "      <th>Destination Wind Direction (sin)</th>\n",
       "      <th>Destination Wind Direction (cos)</th>\n",
       "      <th>Destination Wind Gust</th>\n",
       "      <th>Destination Visibility</th>\n",
       "      <th>Destination Ceiling</th>\n",
       "      <th>Destination Ceiling Missing</th>\n",
       "      <th>Destination Sea Level Pressure</th>\n",
       "      <th>Destination Sea Level Pressure Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Delay Bin, Month (sin), Month (cos), Day (sin), Day (cos), Day of Week (sin), Day of Week (cos), Scheduled Departure Total Minutes (sin), Scheduled Departure Total Minutes (cos), Scheduled Elapsed Time, Carrier Code, Destination Airport, Manufacturer, Model, Aircraft Age, Aircraft Age Missing, Type of Engine, Number of Seats, Builder Type Certificated, Precipitation Accumulation One Hour, Precipitation Accumulation Six Hours, Air Temperature, Dew Point Temperature, Relative Humidity, Wind Speed, Wind Direction (sin), Wind Direction (cos), Wind Gust, Visibility, Ceiling, Ceiling Missing, Sea Level Pressure, Sea Level Pressure Missing, Destination Precipication Accumulation One Hour, Destination Precipitation Six Hours, Destination Air Temperature, Destination Dew Point Temperature, Destination Relative Humidity, Destination Wind Speed, Destination Wind Direction (sin), Destination Wind Direction (cos), Destination Wind Gust, Destination Visibility, Destination Ceiling, Destination Ceiling Missing, Destination Sea Level Pressure, Destination Sea Level Pressure Missing]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 47 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unknown category col and inspect\n",
    "unknown_col = cat_names[4]\n",
    "unknown_vals = set(x_test[unknown_col].unique()) - set(x_train[unknown_col].unique())\n",
    "\n",
    "# display\n",
    "print(f'Affected column: {unknown_col}')\n",
    "print(f'Unknown values: {unknown_vals}')\n",
    "delays_df[delays_df['Destination Airport'] == 'BUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into col names\n",
    "encoded_feature_names = preprocessor.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df versions\n",
    "x_train_processed_df = pd.DataFrame(x_train_bal, columns=encoded_feature_names)\n",
    "x_test_processed_df = pd.DataFrame(x_test_processed, columns=encoded_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export df as zipped csv\n",
    "def export_zipped_file(df, name):\n",
    "    \n",
    "    # set up output path\n",
    "    output_path = f'Output/Split_Train_Test/sqlite/{name}.zip'\n",
    "\n",
    "    # export\n",
    "    df.to_csv(\n",
    "        output_path,\n",
    "        index=False,\n",
    "        compression={\n",
    "            'method': 'zip',\n",
    "            'archive_name': f'{name}.csv'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to zipped files\n",
    "export_zipped_file(y_train_bal, 'y_train')\n",
    "export_zipped_file(x_train_processed_df, 'x_train')\n",
    "export_zipped_file(y_test, 'y_test')\n",
    "export_zipped_file(x_test_processed_df, 'x_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
